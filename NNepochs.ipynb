{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70b7337b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\numai\\AppData\\Local\\Temp\\ipykernel_9044\\2216524246.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print('Normal Consumers:                    ', y[y['FLAG'] == 0].count()[0])\n",
      "C:\\Users\\numai\\AppData\\Local\\Temp\\ipykernel_9044\\2216524246.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print('Consumers with Fraud:                ', y[y['FLAG'] == 1].count()[0])\n",
      "C:\\Users\\numai\\AppData\\Local\\Temp\\ipykernel_9044\\2216524246.py:30: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(\"Classification assuming no fraud:     %.2f\" % (y[y['FLAG'] == 0].count()[0] / y.shape[0] * 100), \"%\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Consumers:                     36677\n",
      "Consumers with Fraud:                 3579\n",
      "Total Consumers:                      40256\n",
      "Classification assuming no fraud:     91.11 %\n",
      "Test set assuming no fraud:           90.78 %\n",
      "\n",
      "2D - Convolutional Neural Network:\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " module_wrapper_9 (ModuleWra  (1, 142, 5, 32)          704       \n",
      " pper)                                                           \n",
      "                                                                 \n",
      " module_wrapper_10 (ModuleWr  (1, 22720)               0         \n",
      " apper)                                                          \n",
      "                                                                 \n",
      " module_wrapper_11 (ModuleWr  (1, 1)                   22721     \n",
      " apper)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,425\n",
      "Trainable params: 23,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch: 1\n",
      "126/126 [==============================] - 0s 2ms/step\n",
      "Accuracy 91.03328365623447\n",
      "RMSE: 0.2994447585743575\n",
      "MAE: 0.08966716343765524\n",
      "F1: [95.28412802  9.06801008]\n",
      "AUC: 52.31643688629466\n",
      "[[3647    8]\n",
      " [ 353   18]] \n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 0s 2ms/step\n",
      "Accuracy 92.00198708395429\n",
      "RMSE: 0.2828075832796162\n",
      "MAE: 0.07998012916045703\n",
      "F1: [95.74973601 32.35294118]\n",
      "AUC: 59.99432155486152\n",
      "[[3627   28]\n",
      " [ 294   77]] \n",
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 0s 1ms/step\n",
      "Accuracy 92.30004967709885\n",
      "RMSE: 0.2774878433896005\n",
      "MAE: 0.07699950322901143\n",
      "F1: [95.82772544 50.1607717 ]\n",
      "AUC: 69.72466915682465\n",
      "[[3560   95]\n",
      " [ 215  156]] \n",
      "\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 0s 2ms/step\n",
      "Accuracy 92.15101838052658\n",
      "RMSE: 0.2801603401531598\n",
      "MAE: 0.07848981619473423\n",
      "F1: [95.72972973 51.53374233]\n",
      "AUC: 71.09568180058334\n",
      "[[3542  113]\n",
      " [ 203  168]] \n",
      "\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 0s 2ms/step\n",
      "Accuracy 90.43715846994536\n",
      "RMSE: 0.30923844408570295\n",
      "MAE: 0.09562841530054644\n",
      "F1: [94.68452299 52.41038319]\n",
      "AUC: 75.4797733046707\n",
      "[[3429  226]\n",
      " [ 159  212]] \n",
      "\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 0s 2ms/step\n",
      "Accuracy 91.57973174366617\n",
      "RMSE: 0.29017698489600846\n",
      "MAE: 0.08420268256333831\n",
      "F1: [95.37958294 52.58741259]\n",
      "AUC: 73.20286429622308\n",
      "[[3499  156]\n",
      " [ 183  188]] \n",
      "\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 0s 2ms/step\n",
      "Accuracy 91.20715350223547\n",
      "RMSE: 0.2965273427150443\n",
      "MAE: 0.08792846497764531\n",
      "F1: [95.13468939 54.3814433 ]\n",
      "AUC: 75.78275891313085\n",
      "[[3461  194]\n",
      " [ 160  211]] \n",
      "\n",
      "Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 169\u001b[0m\n\u001b[0;32m    164\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m read_data()\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# Uncomment any model to test\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# ANN(X_train, X_test, y_train, y_test)\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m# CNN1D(X_train, X_test, y_train, y_test)\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m \u001b[43mCNN2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 158\u001b[0m, in \u001b[0;36mCNN2D\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch:\u001b[39m\u001b[38;5;124m\"\u001b[39m, i)\n\u001b[1;32m--> 158\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m (model\u001b[38;5;241m.\u001b[39mpredict(X_test_reshaped)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    160\u001b[0m     results(y_test, prediction)\n",
      "File \u001b[1;32mD:\\Python\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\Python\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mD:\\Python\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\Python\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mD:\\Python\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mD:\\Python\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mD:\\Python\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mD:\\Python\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, confusion_matrix, \\\n",
    "    precision_recall_fscore_support, roc_auc_score\n",
    "from tensorflow.keras import Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.layers import Dense, Conv1D, Flatten, Conv2D\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "epochs_number = 1  # number of epochs for the neural networks\n",
    "test_set_size = 0.1  # percentage of the test size comparing to the whole dataset\n",
    "oversampling_flag = 0  # set to 1 to over-sample the minority class\n",
    "oversampling_percentage = 0.2  # percentage of the minority class after the oversampling comparing to majority class\n",
    "\n",
    "\n",
    "# Definition of functions\n",
    "def read_data():\n",
    "    rawData = pd.read_csv('preprocessedR.csv')\n",
    "\n",
    "    # Setting the target and dropping the unnecessary columns\n",
    "    y = rawData[['FLAG']]\n",
    "    X = rawData.drop(['FLAG', 'CONS_NO'], axis=1)\n",
    "\n",
    "    print('Normal Consumers:                    ', y[y['FLAG'] == 0].count()[0])\n",
    "    print('Consumers with Fraud:                ', y[y['FLAG'] == 1].count()[0])\n",
    "    print('Total Consumers:                     ', y.shape[0])\n",
    "    print(\"Classification assuming no fraud:     %.2f\" % (y[y['FLAG'] == 0].count()[0] / y.shape[0] * 100), \"%\")\n",
    "\n",
    "    # columns reindexing according to dates\n",
    "    X.columns = pd.to_datetime(X.columns)\n",
    "    X = X.reindex(X.columns, axis=1)\n",
    "\n",
    "    # Splitting the dataset into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y['FLAG'], test_size=test_set_size, random_state=0)\n",
    "    print(\"Test set assuming no fraud:           %.2f\" % (y_test[y_test == 0].count() / y_test.shape[0] * 100), \"%\\n\")\n",
    "\n",
    "    # Oversampling of minority class to encounter the imbalanced learning\n",
    "    if oversampling_flag == 1:\n",
    "        over = SMOTE(sampling_strategy=oversampling_percentage, random_state=0)\n",
    "        X_train, y_train = over.fit_resample(X_train, y_train)\n",
    "        print(\"Oversampling statistics in training set: \")\n",
    "        print('Normal Consumers:                    ', y_train[y_train == 0].count())\n",
    "        print('Consumers with Fraud:                ', y_train[y_train == 1].count())\n",
    "        print(\"Total Consumers                      \", X_train.shape[0])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def results(y_test, prediction):\n",
    "    print(\"Accuracy\", 100 * accuracy_score(y_test, prediction))\n",
    "    print(\"RMSE:\", mean_squared_error(y_test, prediction, squared=False))\n",
    "    print(\"MAE:\", mean_absolute_error(y_test, prediction))\n",
    "    print(\"F1:\", 100 * precision_recall_fscore_support(y_test, prediction)[2])\n",
    "    print(\"AUC:\", 100 * roc_auc_score(y_test, prediction))\n",
    "    print(confusion_matrix(y_test, prediction), \"\\n\")\n",
    "\n",
    "\n",
    "def ANN(X_train, X_test, y_train, y_test):\n",
    "    print('Artificial Neural Network:')\n",
    "\n",
    "    # Model creation\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1000, input_dim=1034, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss=keras.losses.binary_crossentropy,\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    for i in range(1, 100, 3):\n",
    "        print(\"Epoch:\", i)\n",
    "        model.fit(X_train, y_train, validation_split=0, epochs=i, shuffle=True, verbose=0)\n",
    "        prediction = model.predict_classes(X_test)\n",
    "        results(y_test, prediction)\n",
    "\n",
    "\n",
    "def CNN1D(X_train, X_test, y_train, y_test):\n",
    "    print('1D - Convolutional Neural Network:')\n",
    "\n",
    "    # Transforming the dataset into tensors\n",
    "    X_train = X_train.to_numpy().reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.to_numpy().reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "    # Model creation\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(100, kernel_size=7, input_shape=(1034, 1), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss=keras.losses.binary_crossentropy,\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    for i in range(1, 100, 3):\n",
    "        print(\"Epoch:\", i)\n",
    "        model.fit(X_train, y_train, epochs=i, validation_split=0.1, shuffle=False, verbose=0)\n",
    "        prediction = model.predict_classes(X_test)\n",
    "\n",
    "        results(y_test, prediction)\n",
    "\n",
    "\n",
    "def CNN2D(X_train, X_test, y_train, y_test):\n",
    "    print('2D - Convolutional Neural Network:')\n",
    "\n",
    "    # Transforming every row of the train set into a 2D array and then into a tensor\n",
    "    n_array_X_train = X_train.to_numpy()\n",
    "    n_array_X_train_extended = np.hstack((n_array_X_train, np.zeros(\n",
    "        (n_array_X_train.shape[0], 2))))  # adding two empty columns in order to make the number of columns\n",
    "    # an exact multiple of 7\n",
    "    week = []\n",
    "    for i in range(n_array_X_train_extended.shape[0]):\n",
    "        a = np.reshape(n_array_X_train_extended[i], (-1, 7, 1))\n",
    "        week.append(a)\n",
    "    X_train_reshaped = np.array(week)\n",
    "\n",
    "    # Transforming every row of the train set into a 2D array and then into a tensor\n",
    "    n_array_X_test = X_test.to_numpy()  # X_test to 2D - array\n",
    "    n_array_X_train_extended = np.hstack((n_array_X_test, np.zeros((n_array_X_test.shape[0], 2))))\n",
    "    week2 = []\n",
    "    for i in range(n_array_X_train_extended.shape[0]):\n",
    "        b = np.reshape(n_array_X_train_extended[i], (-1, 7, 1))\n",
    "        week2.append(b)\n",
    "    X_test_reshaped = np.array(week2)\n",
    "\n",
    "    input_shape = (1, 148, 7, 1)  # input shape of the tensor\n",
    "\n",
    "    # Model creation\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(kernel_size=(7, 3), filters=32, input_shape=input_shape[1:], activation='relu',\n",
    "                     data_format='channels_last'))\n",
    "    model.add(Flatten())\n",
    "    # model.add(Dense(100, activation='relu'))\n",
    "    # model.add(Dense(100, activation='relu'))\n",
    "    # model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss=keras.losses.binary_crossentropy,\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    model.build(input_shape)\n",
    "    model.summary()\n",
    "\n",
    "    for i in range(1, 100, 3):\n",
    "        print(\"Epoch:\", i)\n",
    "        model.fit(X_train_reshaped, y_train, validation_split=0.1, epochs=i, shuffle=False, verbose=0)\n",
    "        prediction = (model.predict(X_test_reshaped)>0.5).astype(\"int32\")\n",
    "        results(y_test, prediction)\n",
    "\n",
    "\n",
    "# ----Main----\n",
    "X_train, X_test, y_train, y_test = read_data()\n",
    "\n",
    "# Uncomment any model to test\n",
    "# ANN(X_train, X_test, y_train, y_test)\n",
    "# CNN1D(X_train, X_test, y_train, y_test)\n",
    "CNN2D(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1419c482-8c55-49ba-9b48-0605387de6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
